{"cells":[{"cell_type":"code","source":["spark.conf.set(\"spark.sql.parquet.vorder.enabled\", \"true\")\n","spark.conf.set(\"spark.microsoft.delta.optimizeWrite.enabled\", \"true\")\n","spark.conf.set(\"spark.microsoft.delta.optimizeWrite.binSize\", \"1073741824\")\n","spark.conf.set(\"spark.microsoft.delta.allowArbitraryProperties.enabled\", \"true\")\n","spark.conf.set(\"spark.databricks.delta.allowArbitraryProperties.enabled\", \"true\")\n","spark.conf.set(\"spark.microsoft.delta.retryWriteConflict.enabled\",\"true\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"52c46b99-498f-4d66-95de-9f59d408d195"},{"cell_type":"markdown","source":["# ðŸ“ƒ Parameters"],"metadata":{},"id":"63409bdd-f592-4fd9-a907-a228dfbb2888"},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"55783a74-3fd9-4401-8a7d-953640ced96b"},{"cell_type":"markdown","source":["# ðŸ”— Imports"],"metadata":{},"id":"2017b990-2f2a-4a0b-beb8-b5220e14436d"},{"cell_type":"code","source":["#%run NB_Raw_Functions\n","from notebookutils import mssparkutils\n","from pyspark.sql.types import *\n","from pyspark.sql.functions import *\n","from pyspark.sql.window import Window\n","from delta.tables import *\n","from datetime import datetime, timedelta\n","import pandas as pd\n","import ast\n","import json\n","import pytz\n","import time"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"88d52be8-27e4-4dac-933a-3f0f095240ac"},{"cell_type":"markdown","source":["#### Get Lakehouse Details"],"metadata":{},"id":"dd151c01-4388-4cd8-8ee2-dc6820b07230"},{"cell_type":"code","source":["\n","def get_Lakehouse_Details():\n","    lh_id = -1\n","    for mp in mssparkutils.fs.mounts():\n","        if mp.mountPoint == \"/default\":\n","            # print(f\"Default Lakehouse is: {mp.source}\")\n","            lh_id = mp.source.split(\"microsoft.com/\", 1)[-1]\n","            # print(lh_id)\n","            lh_details_json = mssparkutils.lakehouse.get(name=lh_id)\n","            lh_name = lh_details_json[\"displayName\"]\n","    if lh_name == \"\":\n","        mssparkutils.notebook.exit(\"LH_Logging cannot be mounted\")\n","\n","    return lh_details_json"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"22d6bbad-992a-4321-8b16-58b00a182774"},{"cell_type":"code","source":["def execute_SQL_with_retry(sql_query, retries=3, delays=[30, 60, 120]):\n","    attempt = 0\n","    while attempt < retries:\n","        try:\n","            print(f\"Attempt: {attempt}\")\n","            sql_output = spark.sql(sql_query)\n","            return sql_output\n","        except Exception as e:\n","            if attempt < len(delays):\n","                time.sleep(delays[attempt])\n","                print(f\"Retry Attempt: {attempt} Failed\")\n","            attempt += 1\n","            if attempt == retries:\n","                print(f\"Failed after {retries} attempts: {e}\")\n","                return None  # Return None instead of raising the exception"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c41aecb8-38f5-4bd0-beb6-2b0c995cfccf"},{"cell_type":"markdown","source":["#### Logging Functions for Notebooks"],"metadata":{},"id":"9dcf5ff1-c19c-4bb5-831a-ad9037a2f7ea"},{"cell_type":"markdown","source":["##### log_Initialise"],"metadata":{},"id":"c38a8911-298a-4a93-b143-61e2741260e9"},{"cell_type":"markdown","source":["##### Notebook_log_Initialise"],"metadata":{},"id":"8832aa68-f9f1-43bf-b609-1d3d5af7a452"},{"cell_type":"code","source":["def Notebook_log_Initialise(Log_Lakehouse_Name, Source_System_Code, Notebook_Name, Parent_Log_ID, inserted_log_id, current_datetime_utc):\n","\n","    # variables\n","    error_description = \"\"\n","    load_status = \"\"\n","\n","    #If No ParentID was Passed then insert 0\n","    if Parent_Log_ID == \"\":\n","        Parent_Log_ID = \"0\"\n","\n","    Parent_Log_Insert = str(Parent_Log_ID) + \" as Parent_Log_ID, \"\n","\n","    # create log\n","    try:\n","        # Insert new record into Notebook_Execution_Log\n","        insert_sql1 = (\n","            \"\"\"INSERT INTO \"\"\"\n","            + Log_Lakehouse_Name\n","            + \"\"\".Notebook_Execution_Log \n","                        (Parent_Log_ID, \n","                        Log_ID, \n","                        Source_System_Code, \n","                        Notebook_Name, \n","                        Run_Start_DateTime, \n","                        Run_End_DateTime, \n","                        Run_Status, \n","                        Run_Message, \n","                        Created_DateTime, \n","                        Modified_DateTime\n","                        )\n","            \"\"\"\n","        )\n","\n","        insert_sql1 += (\n","            \"SELECT \"\n","            #+ Parent_Log_ID \n","            + Parent_Log_Insert\n","            + str(inserted_log_id)\n","            + \", '\"\n","            + Source_System_Code\n","            + \"', '\"\n","            + Notebook_Name\n","            + \"', '\"\n","            + current_datetime_utc\n","            + \"', NULL AS Run_End_DateTime, \"\n","            + \"'\" + \"\"\"InProgress\"\"\" + \"'\" + \" AS Run_Status, \"\n","            + \"'\" + \"\"\"Initialised\"\"\" + \"'\" + \" AS Run_Message, '\"\n","            + current_datetime_utc\n","            + \"', '\"\n","            + current_datetime_utc\n","            + \"'\"\n","        )\n","\n","\n","        # print(\"insert_SQL: \" + insert_sql1)\n","        sql_output = execute_SQL_with_retry(insert_sql1, 3, 30)\n","\n","        # print(sql_output)\n","\n","    except Exception as e:\n","        error_description += f\"{e}\"\n","        error_description = error_description.replace(\"'\", \"\")\n","        load_status = \"FAILURE log_Initialise\"\n","\n","        print(\"loadStatus: \" + load_status)\n","        print(\"errorDescription: \" + error_description)\n","\n","    \n","    result = {\n","        \"Inserted_Log_ID\": str(inserted_log_id),\n","        \"LoadStatus\": load_status,\n","        \"errorDescription\": error_description,\n","    }\n","\n","    # Convert result to JSON correct string and ensure the result is returned as a JSON object\n","    #result_json_str = json.dumps(result, indent=4)\n","    #result = json.loads(result_json_str)\n","\n","    return result"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"09345531-45f0-4ad8-9523-6bd7be38d92d"},{"cell_type":"code","source":["def Notebook_log_Update(Log_Lakehouse_Name, Source_System_Code, varNotebookName, inserted_log_id, run_status, run_message, current_datetime_utc_end, error_description):\n","\n","    #current_datetime_utc_end = current_datetime.strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n","    error_description = error_description.replace(\"'\", \"\")\n","\n","    if not error_description == \"\":\n","        run_message = error_description\n","\n","    # update Notebook_Execution_Log\n","    try:\n","        update_sql = (\n","            \"\"\"UPDATE \"\"\"\n","            + Log_Lakehouse_Name\n","            + \"\"\".Notebook_Execution_Log\n","                    SET Run_Status = '\"\"\"\n","            + run_status\n","            + \"\"\"', \n","                    Run_Message = '\"\"\"\n","            + run_message\n","            + \"\"\"',\n","                    Run_End_DateTime = '\"\"\"\n","            + current_datetime_utc_end\n","            + \"\"\"',\n","                    Modified_DateTime = '\"\"\"\n","            + current_datetime_utc_end\n","            + \"\"\"'\n","                    WHERE Notebook_Name = '\"\"\"\n","            + varNotebookName\n","            + \"\"\"' \n","                        AND Log_ID = '\"\"\"\n","            + str(inserted_log_id)\n","            + \"\"\"'\"\"\"\n","        )\n","\n","        # print(\"update_sql: \" + update_sql)\n","        execute_SQL_with_retry(update_sql, 3, 30)\n","        print()\n","        # raise Exception(errorDescription[0:200])\n","\n","    except Exception as e:\n","        error_description += f\"{e}\"\n","        error_description = error_description.replace(\"'\", \"\")\n","        run_status = \"FAILURE\"\n","\n","        print(\"loadStatus: \" + run_status)\n","        print(\"errorDescription: \" + error_description)\n","\n","    result = {\n","        \"Log_ID\": inserted_log_id,\n","        \"LoadStatus\": run_status,\n","        \"errorDescription\": error_description,\n","    }\n","    # Convert result to JSON correct string and ensure the result is returned as a JSON object\n","    # result_json_str = json.dumps(result, indent=4)\n","    # result = json.loads(result_json_str)\n","    return result"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b52322a7-000b-4803-82d0-115a0f4c9e62"},{"cell_type":"markdown","source":["##### Notebook_Param_Insert"],"metadata":{},"id":"0dd9af2d-f60a-420a-a084-50a71f2bbb29"},{"cell_type":"code","source":["def Notebook_Param_Insert(Log_Lakehouse_Name, Notebook_Name, Notebook_Table, NotebookLogId, ExecutionParameters):\n","    \n","    error_description = \"\"\n","    \n","    ExecutionParameters = ExecutionParameters.replace(\"'\", \"~~\")\n","\n","       # create log\n","    try:\n","        # Insert new record into Notebook_Execution_Log\n","        insert_sql1 = (\n","            \"\"\"INSERT INTO \"\"\"\n","            + Log_Lakehouse_Name\n","            + \"\"\".Notebook_Execution_Parameters \n","                        (Log_ID, \n","                        Notebook_Name, \n","                        Notebook_Table, \n","                        ExecutionParameters\n","                        )\n","            \"\"\"\n","        )\n","\n","        insert_sql1 += (\n","            \"SELECT \"\n","            + str(NotebookLogId)\n","            + \", '\"\n","            + Notebook_Name\n","            + \"', '\"\n","            + Notebook_Table\n","            + \"', '\"\n","            + ExecutionParameters\n","            + \"'\"\n","        )\n","\n","\n","        # print(\"insert_SQL: \" + insert_sql1)\n","        sql_output = execute_SQL_with_retry(insert_sql1, 3, 30)\n","\n","        # print(sql_output)\n","\n","    except Exception as e:\n","        error_description += f\"{e}\"\n","        error_description = error_description.replace(\"'\", \"\")\n","\n","        print(\"errorDescription: \" + error_description)\n","\n","    \n","    result = {\n","        \"Param_Log_ID\": str(NotebookLogId),\n","        \"errorDescription\": error_description,\n","    }\n","\n","    # Convert result to JSON correct string and ensure the result is returned as a JSON object\n","    #result_json_str = json.dumps(result, indent=4)\n","    #result = json.loads(result_json_str)\n","\n","    return result"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fbec0fb9-caef-413f-8126-a7104a751aeb"},{"cell_type":"code","source":["def Notebook_Param_Select(Log_Lakehouse_Name, NotebookLogId):\n","    \n","    error_description = \"\"\n","\n","    try:\n","        select_sql = (\"select ExecutionParameters from \"+Log_Lakehouse_Name+\".Notebook_Execution_Parameters where Log_ID = \"+ str(NotebookLogId))\n","\n","    except Exception as e:\n","        error_description += f\"{e}\"\n","        error_description = error_description.replace(\"'\", \"\")\n","        load_status = \"FAILURE\"\n","\n","    ExecutionParameters = execute_SQL_with_retry(select_sql, 3, 30)\n","    \n","    ExecutionParameters = ExecutionParameters.replace(\"~~\", \"'\")\n","\n","    return ExecutionParameters"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c26d84cf-1092-4d29-96ff-1e02b044eed0"},{"cell_type":"markdown","source":["##### Notebook_Detail_Log"],"metadata":{},"id":"844c3db3-2b5f-481f-9bd4-53c99432d246"},{"cell_type":"code","source":["def Notebook_Detail_log_Initialise(Log_Lakehouse_Name, Data_Movement, Notebook_Name, log_id, current_datetime_utc, Source_Object_Name, Target_Object_Name):\n","\n","    # variables\n","    error_description = \"\"\n","    load_status = \"\"\n","\n","   \n","    try:\n","        # Insert new records into Notebook_Execution_Log_Details\n","        insert_sql2 = (\n","            \"\"\"INSERT INTO \"\"\"\n","            + Log_Lakehouse_Name\n","            + \"\"\".Notebook_Execution_Log_Details \n","            (Log_ID,\n","            Data_Movement,\n","            Notebook_Name,\n","            Source_Object_Name,\n","            Target_Object_Name,\n","            Files_Read,\n","            Files_Written,\n","            Rows_Read,\n","            Rows_Affected,\n","            Rows_Inserted,\n","            Rows_Updated,\n","            Rows_Deleted,\n","            Created_DateTime,\n","            Modified_DateTime\n","            )\"\"\"\n","        )\n","        \n","        insert_sql2 += (\n","                        \"SELECT \"\n","                        + str(log_id)\n","                        + \", '\"\n","                        + Data_Movement\n","                        + \"', '\"\n","                        + Notebook_Name\n","                        + \"', '\"\n","                        + Source_Object_Name\n","                        + \"', '\"\n","                        + Target_Object_Name\n","                        + \"', \"\n","                        + \"NULL AS Files_Read, NULL AS Files_Written, \"\n","                        + \"NULL AS Rows_Read, NULL AS Rows_Affected, NULL AS Rows_Inserted, NULL AS Rows_Updated, NULL AS Rows_Deleted, '\"\n","                        + current_datetime_utc\n","                        + \"', '\"\n","                        + current_datetime_utc\n","                        + \"'\"\n","                    )\n","\n","        # print(\"insert_SQL: \" + insert_sql2)\n","        DetailLog_sql_output = execute_SQL_with_retry(insert_sql2, 3, 30)\n","\n","    except Exception as e:\n","        error_description += f\"{e}\"\n","        error_description = error_description.replace(\"'\", \"\")\n","        load_status = \"FAILURE\"\n","\n","        print(\"loadStatus: \" + load_status)\n","        print(\"errorDescription: \" + error_description)\n","\n","    \n","    result = {\n","        \"Inserted_Log_Detail_ID\": str(log_id),\n","        \"LoadStatus\": load_status,\n","        \"errorDescription\": error_description,\n","    }\n","\n","    return result"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e4609fa5-4083-43c1-9900-3a46bce4cd56"},{"cell_type":"code","source":["def Notebook_Detail_log_Update(Log_Lakehouse_Name, Notebook_Name, log_id,  Target_Object_Name, Files_Read, Files_Written, Rows_Read, Rows_Affected, Rows_Inserted, Rows_Updated, Rows_Deleted, current_datetime_utc_end):\n","\n","    load_status = \"Completed\"\n","    error_description = \"\"\n","    # update Notebook_Detail_Execution_Log\n","    try:\n","        update_sql = (\n","            \"\"\"UPDATE \"\"\"\n","            + Log_Lakehouse_Name\n","            + \"\"\".Notebook_Execution_Log_Details\n","                    SET Files_Read = '\"\"\"\n","            + Files_Read\n","            + \"\"\"', \n","                    Files_Written = '\"\"\"\n","            + Files_Written\n","            + \"\"\"',\n","                    Rows_Read = '\"\"\"\n","            + Rows_Read\n","            + \"\"\"',\n","                    Rows_Affected = '\"\"\"\n","            + Rows_Affected\n","            + \"\"\"',\n","                    Rows_Inserted = '\"\"\"\n","            + Rows_Inserted\n","            + \"\"\"',\n","                    Rows_Updated = '\"\"\"\n","            + Rows_Updated\n","            + \"\"\"',\n","                    Rows_Deleted = '\"\"\"\n","            + Rows_Deleted\n","            + \"\"\"',\n","                    Modified_DateTime = '\"\"\"\n","            + current_datetime_utc_end\n","            + \"\"\"'\n","                    WHERE Notebook_Name = '\"\"\"\n","            + Notebook_Name\n","            + \"\"\"' \n","                        AND Target_Object_Name = '\"\"\"\n","            + Target_Object_Name\n","            + \"\"\"' \n","                        AND Log_ID = '\"\"\"\n","            + str(log_id)\n","            + \"\"\"'\"\"\"\n","        )\n","\n","        # print(\"update_sql: \" + update_sql)\n","        execute_SQL_with_retry(update_sql, 3, 30)\n","        print()\n","        # raise Exception(errorDescription[0:200])\n","\n","    except Exception as e:\n","        error_description += f\"{e}\"\n","        error_description = error_description.replace(\"'\", \"\")\n","        load_status = \"FAILURE\"\n","\n","        print(\"loadStatus: \" + load_status)\n","        print(\"errorDescription: \" + error_description)\n","\n","    result = {\n","        \"Log_ID\": str(log_id),\n","        \"LoadStatus\": load_status,\n","        \"errorDescription\": error_description,\n","    }\n","    # Convert result to JSON correct string and ensure the result is returned as a JSON object\n","    # result_json_str = json.dumps(result, indent=4)\n","    # result = json.loads(result_json_str)\n","    return result"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4505d6a9-3fe7-477b-91a3-7d02aba96282"},{"cell_type":"markdown","source":["##### log_Update"],"metadata":{},"id":"9a316b12-9eb6-4c85-b68f-cbd2e61f4b6c"},{"cell_type":"markdown","source":["log_Update"],"metadata":{},"id":"f050d236-e335-4db9-a68d-f367132a3f5c"},{"cell_type":"markdown","source":["# ðŸ—„ï¸ Prepare Logging"],"metadata":{},"id":"21ad7da7-b44c-4fd8-a380-840d229bba67"},{"cell_type":"markdown","source":["## Create Tables"],"metadata":{},"id":"c252330c-bfad-4a87-a567-6cf1079cd322"},{"cell_type":"code","source":["sql_query = f\"\"\"\n","CREATE TABLE IF NOT EXISTS LH_Logging.Notebook_Execution_Parameters\n","(\n","    Log_ID BIGINT NOT NULL,\n","    Notebook_Name STRING NOT NULL, \n","    Notebook_Table STRING NOT NULL,\n","    ExecutionParameters STRING NOT NULL\n",")\n","USING DELTA\n","PARTITIONED BY (Log_ID, Notebook_Table);\n","\"\"\"\n","sql_output = execute_SQL_with_retry(sql_query)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0dc86388-4705-40df-9e65-aa9da66e868f"},{"cell_type":"code","source":["sql_query = f\"\"\"\n","CREATE TABLE IF NOT EXISTS LH_Logging.Notebook_Execution_Log\n","(\n","    Log_ID BIGINT NOT NULL,\n","    Parent_Log_ID BIGINT,\n","    Source_System_Code STRING NOT NULL,\n","    Notebook_Name STRING NOT NULL,\n","    Run_Start_DateTime TIMESTAMP NOT NULL,\n","    Run_End_DateTime TIMESTAMP,\n","    Run_Status STRING NOT NULL,\n","    Run_Message STRING NOT NULL,\n","    Created_DateTime TIMESTAMP NOT NULL,\n","    Modified_DateTime TIMESTAMP NOT NULL\n",")\n","USING DELTA\n","PARTITIONED BY (Log_ID, Notebook_Name);\n","\"\"\"\n","sql_output = execute_SQL_with_retry(sql_query)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b30f94ca-ae39-4b71-a33b-2d1fae46f860"},{"cell_type":"code","source":["sql_query = f\"\"\"\n","CREATE TABLE IF NOT EXISTS LH_Logging.Notebook_Execution_Log_Details\n","(\t\n","\tLog_ID BIGINT NOT NULL,\n","\tData_Movement STRING NOT NULL, --Source to Raw, Raw to Trusted, etc.\n","\tNotebook_Name STRING NOT NULL,\n","\tSource_Object_Name STRING NOT NULL,\n","\tTarget_Object_Name STRING NOT NULL,\n","\tFiles_Read BIGINT,\n","\tFiles_Written BIGINT,\n","\tRows_Read BIGINT,\n","\tRows_Affected BIGINT,\n","\tRows_Inserted BIGINT,\n","\tRows_Updated BIGINT,\n","\tRows_Deleted BIGINT,\n","\tCreated_DateTime TIMESTAMP NOT NULL,\n","\tModified_DateTime TIMESTAMP NOT NULL\n",")\t\n","USING DELTA\n","PARTITIONED BY (Log_ID, Target_Object_Name, Notebook_Name);\n","\"\"\"\n","sql_output = execute_SQL_with_retry(sql_query)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"026d1927-eae4-401c-98db-7611efea1a65"},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d0e53953-42e8-4db5-aa43-0f46162e1ceb"}],"metadata":{"language_info":{"name":"python"},"kernel_info":{"name":"synapse_pyspark"},"a365ComputeOptions":null,"sessionKeepAliveTimeout":0,"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":null}},"nbformat":4,"nbformat_minor":5}